{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "library(doMC)\n",
    "library(survival)\n",
    "library(data.table)\n",
    "library(mltools)\n",
    "library(CoxBoost)\n",
    "library(randomForestSRC)\n",
    "library(CoxHD)\n",
    "source('run_prognosis.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all <-read.table(\"df_prognosis.tsv\",sep = '\\t' , header = T) \n",
    "\n",
    "###    2094 rows 166 columns\n",
    "\n",
    "df_all <-na.omit(df_all) # delete rows with na (161)\n",
    "df_all <- df_all[df_all$os>0,] # delete when os is negative (2)\n",
    "\n",
    "####\n",
    "\n",
    "#Convert predicted_component to one hot encoder\n",
    "df_all$new_eln<-factor(df_all$new_eln, levels = c(\"adverse\",\"intermediate\",\"favorable\"), labels = 0:2, ordered = TRUE)  # convert categorical new_eln to numerical (0,1,2)\n",
    "name <-rownames(df_all)\n",
    "df_all$predicted_component <- as.factor(df_all$predicted_component)\n",
    "df_final <- as.data.frame(one_hot(as.data.table(df_all),cols=\"predicted_component\"))\n",
    "rownames(df_final) <- name\n",
    "\n",
    "#write.table(df_final,\"df_prognosis_features_ready.tsv\",sep='\\t',quote=F)\n",
    "####\n",
    "\n",
    "###  1931 rows 180 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"start CV\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CoxMod_0.1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.6265973</td></tr>\n",
       "\t<tr><td>0.6511334</td></tr>\n",
       "\t<tr><td>0.6376802</td></tr>\n",
       "\t<tr><td>0.6470114</td></tr>\n",
       "\t<tr><td>0.6554482</td></tr>\n",
       "\t<tr><td>0.6808461</td></tr>\n",
       "\t<tr><td>0.6326469</td></tr>\n",
       "\t<tr><td>0.6370511</td></tr>\n",
       "\t<tr><td>0.6442483</td></tr>\n",
       "\t<tr><td>0.6153510</td></tr>\n",
       "\t<tr><td>0.6390959</td></tr>\n",
       "\t<tr><td>0.6476431</td></tr>\n",
       "\t<tr><td>0.6379850</td></tr>\n",
       "\t<tr><td>0.6345605</td></tr>\n",
       "\t<tr><td>0.6626678</td></tr>\n",
       "\t<tr><td>0.6489270</td></tr>\n",
       "\t<tr><td>0.6490383</td></tr>\n",
       "\t<tr><td>0.6620929</td></tr>\n",
       "\t<tr><td>0.6435715</td></tr>\n",
       "\t<tr><td>0.6278114</td></tr>\n",
       "\t<tr><td>0.6570237</td></tr>\n",
       "\t<tr><td>0.6576372</td></tr>\n",
       "\t<tr><td>0.6085469</td></tr>\n",
       "\t<tr><td>0.6517430</td></tr>\n",
       "\t<tr><td>0.6316241</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       " CoxMod\\_0.1\\\\\n",
       "\\hline\n",
       "\t 0.6265973\\\\\n",
       "\t 0.6511334\\\\\n",
       "\t 0.6376802\\\\\n",
       "\t 0.6470114\\\\\n",
       "\t 0.6554482\\\\\n",
       "\t 0.6808461\\\\\n",
       "\t 0.6326469\\\\\n",
       "\t 0.6370511\\\\\n",
       "\t 0.6442483\\\\\n",
       "\t 0.6153510\\\\\n",
       "\t 0.6390959\\\\\n",
       "\t 0.6476431\\\\\n",
       "\t 0.6379850\\\\\n",
       "\t 0.6345605\\\\\n",
       "\t 0.6626678\\\\\n",
       "\t 0.6489270\\\\\n",
       "\t 0.6490383\\\\\n",
       "\t 0.6620929\\\\\n",
       "\t 0.6435715\\\\\n",
       "\t 0.6278114\\\\\n",
       "\t 0.6570237\\\\\n",
       "\t 0.6576372\\\\\n",
       "\t 0.6085469\\\\\n",
       "\t 0.6517430\\\\\n",
       "\t 0.6316241\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| CoxMod_0.1 |\n",
       "|---|\n",
       "| 0.6265973 |\n",
       "| 0.6511334 |\n",
       "| 0.6376802 |\n",
       "| 0.6470114 |\n",
       "| 0.6554482 |\n",
       "| 0.6808461 |\n",
       "| 0.6326469 |\n",
       "| 0.6370511 |\n",
       "| 0.6442483 |\n",
       "| 0.6153510 |\n",
       "| 0.6390959 |\n",
       "| 0.6476431 |\n",
       "| 0.6379850 |\n",
       "| 0.6345605 |\n",
       "| 0.6626678 |\n",
       "| 0.6489270 |\n",
       "| 0.6490383 |\n",
       "| 0.6620929 |\n",
       "| 0.6435715 |\n",
       "| 0.6278114 |\n",
       "| 0.6570237 |\n",
       "| 0.6576372 |\n",
       "| 0.6085469 |\n",
       "| 0.6517430 |\n",
       "| 0.6316241 |\n",
       "\n"
      ],
      "text/plain": [
       "      CoxMod_0.1\n",
       " [1,] 0.6265973 \n",
       " [2,] 0.6511334 \n",
       " [3,] 0.6376802 \n",
       " [4,] 0.6470114 \n",
       " [5,] 0.6554482 \n",
       " [6,] 0.6808461 \n",
       " [7,] 0.6326469 \n",
       " [8,] 0.6370511 \n",
       " [9,] 0.6442483 \n",
       "[10,] 0.6153510 \n",
       "[11,] 0.6390959 \n",
       "[12,] 0.6476431 \n",
       "[13,] 0.6379850 \n",
       "[14,] 0.6345605 \n",
       "[15,] 0.6626678 \n",
       "[16,] 0.6489270 \n",
       "[17,] 0.6490383 \n",
       "[18,] 0.6620929 \n",
       "[19,] 0.6435715 \n",
       "[20,] 0.6278114 \n",
       "[21,] 0.6570237 \n",
       "[22,] 0.6576372 \n",
       "[23,] 0.6085469 \n",
       "[24,] 0.6517430 \n",
       "[25,] 0.6316241 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dim(df_all)\n",
    "#dim(df_final)\n",
    "df_final <- read.table(\"df_prognosis_features_ready.tsv\",sep = '\\t' , header = T)\n",
    "x <- data.matrix(df_final[,1:84])\n",
    "y <- data.matrix(df_final[,c(\"os\",\"os_status\")])\n",
    "predictors <- c(predictorGLM)\n",
    "#predictors <- c(rep(list(predictorGLM),10),rep(list(predictorRF),10),predictorBoost,predictorRFX)\n",
    "str_predictors <-c(rep(\"CoxMod\",10),rep(\"RFS\",10),\"CoxBoost\",\"RFX\")\n",
    "l_alpha <-seq(0.1,1,0.1)\n",
    "l_ntree <- seq(100,1000,100)\n",
    "launch_prognosis(x,y,predictors,str_predictors,l_alpha,l_ntree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"start CV\"\n",
      "..[1] \"start CV\"\n",
      "..[1] \"start CV\"\n",
      "..[1] \"start CV\"\n",
      ".[1] 10\n",
      ".[1] 10\n",
      "[1] \"start CV\"\n",
      ".[1] 20\n",
      ".[1] 20\n",
      "[1] \"start CV\"\n",
      ".[1] 10\n",
      ".[1] 10\n",
      "[1] \"start CV\"\n",
      ".[1] 20\n",
      ".[1] 20\n",
      "[1] \"start CV\"\n",
      ".."
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>CoxGLM_0.05</th><th scope=col>CoxGLM_0.1</th><th scope=col>CoxGLM_0.15</th><th scope=col>predictorRF_10_10</th><th scope=col>predictorRF_10_20</th><th scope=col>predictorRF_20_10</th><th scope=col>predictorRF_20_20</th><th scope=col>predictorBoost_</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.6478436</td><td>0.6479093</td><td>0.6471204</td><td>0.6398329</td><td>0.6387570</td><td>0.6347908</td><td>0.6448320</td><td>0.6471647</td></tr>\n",
       "\t<tr><td>0.6498326</td><td>0.6485409</td><td>0.6485937</td><td>0.6363847</td><td>0.6407016</td><td>0.6454629</td><td>0.6515815</td><td>0.6474822</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllll}\n",
       " CoxGLM\\_0.05 & CoxGLM\\_0.1 & CoxGLM\\_0.15 & predictorRF\\_10\\_10 & predictorRF\\_10\\_20 & predictorRF\\_20\\_10 & predictorRF\\_20\\_20 & predictorBoost\\_\\\\\n",
       "\\hline\n",
       "\t 0.6478436 & 0.6479093 & 0.6471204 & 0.6398329 & 0.6387570 & 0.6347908 & 0.6448320 & 0.6471647\\\\\n",
       "\t 0.6498326 & 0.6485409 & 0.6485937 & 0.6363847 & 0.6407016 & 0.6454629 & 0.6515815 & 0.6474822\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| CoxGLM_0.05 | CoxGLM_0.1 | CoxGLM_0.15 | predictorRF_10_10 | predictorRF_10_20 | predictorRF_20_10 | predictorRF_20_20 | predictorBoost_ |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 0.6478436 | 0.6479093 | 0.6471204 | 0.6398329 | 0.6387570 | 0.6347908 | 0.6448320 | 0.6471647 |\n",
       "| 0.6498326 | 0.6485409 | 0.6485937 | 0.6363847 | 0.6407016 | 0.6454629 | 0.6515815 | 0.6474822 |\n",
       "\n"
      ],
      "text/plain": [
       "     CoxGLM_0.05 CoxGLM_0.1 CoxGLM_0.15 predictorRF_10_10 predictorRF_10_20\n",
       "[1,] 0.6478436   0.6479093  0.6471204   0.6398329         0.6387570        \n",
       "[2,] 0.6498326   0.6485409  0.6485937   0.6363847         0.6407016        \n",
       "     predictorRF_20_10 predictorRF_20_20 predictorBoost_\n",
       "[1,] 0.6347908         0.6448320         0.6471647      \n",
       "[2,] 0.6454629         0.6515815         0.6474822      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- data.matrix(df_final[,1:84])\n",
    "y <- data.matrix(df_final[,c(\"os\",\"os_status\")])\n",
    "predictors <- c(rep(list(predictorGLM),3),predictorRF,predictorRF,predictorBoost)\n",
    "#predictors <- c(predictorRFX)\n",
    "#predictors <- c(rep(list(predictorGLM),10),rep(list(predictorRF),10),predictorBoost,predictorRFX)\n",
    "str_predictors <-c(rep(\"CoxMod\",10),rep(\"RFS\",10),\"CoxBoost\",\"RFX\")\n",
    "str_predictors <- c(rep(\"CoxGLM\",3),rep(\"predictorRF\",4),\"predictorBoost\")\n",
    "l_alpha <-seq(0.05,1,0.05)\n",
    "#l_ntree <- seq(100,1500,100)\n",
    "l_ntree <-c(10,20)\n",
    "(launch_prognosis(x=x,y=y,predictors=predictors,str_predictors=str_predictors,l_alpha=l_alpha,l_ntree=l_ntree,mc.cores=1,nodesize=c(10,20),nrepeats=1,nfolds=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colnames(df_final)\n",
    "all_features <- 1:177\n",
    "eln_clin<-c(1,169:175)\n",
    "eln_clin_demo<-c(1,169:177)\n",
    "eln_clin_demo_cyto <-c(1,85:153,169:177)\n",
    "eln_clin_demo_gen <-c(1:84,169:177)\n",
    "eln_clin_demo_cyto_gen <-c(1:153,169:177)\n",
    "eln_clin_demo_comp <-c(1,154:177)\n",
    "eln_cyto_gen<-c(1:153)\n",
    "eln_cyto_gen_comp <-c(1:168)\n",
    "eln_cyto_comp <-c(1,85:168)\n",
    "eln_gen_comp <-c(1:84,154:168)\n",
    "\n",
    "clin_demo<-c(169:177)\n",
    "clin_demo_cyto <-c(85:153,169:177)\n",
    "clin_demo_gen <-c(2:84,169:177)\n",
    "clin_demo_cyto_gen <-c(2:153,169:177)\n",
    "clin_demo_comp <-c(154:177)\n",
    "cyto_gen<-c(2:153)\n",
    "cyto_gen_comp <-c(2:168)\n",
    "cyto_comp <-c(85:168)\n",
    "gen_comp <-c(2:84,154:168)\n",
    "clin_demo_cyto_gen_comp<-c(2:177)\n",
    "gen<-c(2:84)\n",
    "cyto<-c(85:153)\n",
    "comp<-c(154:168)\n",
    "a <-list(all_features=all_features,eln_clin=eln_clin,eln_clin_demo=eln_clin_demo,\n",
    "    eln_clin_demo_cyto=eln_clin_demo_cyto,eln_clin_demo_gen=eln_clin_demo_gen,\n",
    "    eln_clin_demo_cyto_gen=eln_clin_demo_cyto_gen,eln_clin_demo_comp=eln_clin_demo_comp,\n",
    "    eln_cyto_gen=eln_cyto_gen,eln_cyto_gen_comp=eln_cyto_gen_comp,eln_cyto_comp=eln_cyto_comp,\n",
    "    eln_gen_comp=eln_gen_comp,clin_demo=clin_demo,clin_demo_cyto=clin_demo_cyto,clin_demo_gen=clin_demo_gen,\n",
    "    clin_demo_cyto_gen=clin_demo_cyto_gen,clin_demo_comp=clin_demo_comp,cyto_gen=cyto_gen,cyto_gen_comp=cyto_gen_comp,\n",
    "    cyto_comp=cyto_comp,gen_comp=gen_comp,clin_demo_cyto_gen_comp=clin_demo_cyto_gen_comp,gen=gen,cyto=cyto,comp=comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"all_features.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_clin.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_clin_demo.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_clin_demo_cyto.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_clin_demo_gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_clin_demo_cyto_gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_clin_demo_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_cyto_gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_cyto_gen_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_cyto_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"eln_gen_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"clin_demo.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"clin_demo_cyto.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"clin_demo_gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"clin_demo_cyto_gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"clin_demo_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"cyto_gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"cyto_gen_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"cyto_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"gen_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"clin_demo_cyto_gen_comp.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"gen.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"cyto.tsv\"\n",
      "[1] \"DONE\"\n",
      "[1] \"comp.tsv\"\n",
      "[1] \"DONE\"\n"
     ]
    }
   ],
   "source": [
    "prognosis_features<- list(all_features=all_features,eln_clin=eln_clin,eln_clin_demo=eln_clin_demo,\n",
    "    eln_clin_demo_cyto=eln_clin_demo_cyto,eln_clin_demo_gen=eln_clin_demo_gen,\n",
    "    eln_clin_demo_cyto_gen=eln_clin_demo_cyto_gen,eln_clin_demo_comp=eln_clin_demo_comp,\n",
    "    eln_cyto_gen=eln_cyto_gen,eln_cyto_gen_comp=eln_cyto_gen_comp,eln_cyto_comp=eln_cyto_comp,\n",
    "    eln_gen_comp=eln_gen_comp,clin_demo=clin_demo,clin_demo_cyto=clin_demo_cyto,clin_demo_gen=clin_demo_gen,\n",
    "    clin_demo_cyto_gen=clin_demo_cyto_gen,clin_demo_comp=clin_demo_comp,cyto_gen=cyto_gen,cyto_gen_comp=cyto_gen_comp,\n",
    "    cyto_comp=cyto_comp,gen_comp=gen_comp,clin_demo_cyto_gen_comp=clin_demo_cyto_gen_comp,gen=gen,cyto=cyto,comp=comp)\n",
    "###--------------------------------------------------\n",
    "y <- data.matrix(df_final[,c(\"os\",\"os_status\")])\n",
    "\n",
    "predictors <- c(rep(list(predictorGLM),20),rep(list(predictorRF),15),predictorBoost,predictorRFX)\n",
    "str_predictors <-c(rep(\"CoxGLM\",20),rep(\"RFS\",105),\"CoxBoost\",\"RFX\")\n",
    "l_alpha <-seq(0.05,1,0.05)\n",
    "l_ntree <- seq(100,1500,100)\n",
    "mc.cores <- 8\n",
    "nodesize <- c(5,10,15,20,30,40,50)\n",
    "for (i in 1:length(prognosis_features)){\n",
    "    x <- data.matrix(df_final[,prognosis_features[[i]]])\n",
    "    print(paste(names(prognosis_features)[i],\".tsv\",sep=\"\"))\n",
    "    print(\"DONE\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final <- read.table(\"df_prognosis_features_ready.tsv\",sep = '\\t' , header = T)\n",
    "x <- data.matrix(df_final[,1:84])\n",
    "y <- data.matrix(df_final[,c(\"os\",\"os_status\")])\n",
    "predictors <- c(rep(list(predictorGLM),20),rep(list(predictorRF),105),predictorBoost,predictorRFX)\n",
    "str_predictors <-c(rep(\"CoxGLM\",20),rep(\"RFS\",105),\"CoxBoost\",\"RFX\")\n",
    "l_alpha <-seq(0.05,1,0.05)\n",
    "l_ntree <- seq(100,1500,100)\n",
    "#write.table(launch_prognosis(x,y,predictors,str_predictors,l_alpha,l_ntree),\"tests.tsv\",quote=F,sep='\\t')\n",
    "launch_prognosis(x=x,y=y,predictors=predictors,str_predictors=str_predictors,l_alpha=l_alpha,l_ntree=l_ntree,mc.cores=8,nodesize=c(5,10,15,20,30,40,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"start CV\"\n",
      ".........."
     ]
    },
    {
     "data": {
      "text/html": [
       "0.647480572327078"
      ],
      "text/latex": [
       "0.647480572327078"
      ],
      "text/markdown": [
       "0.647480572327078"
      ],
      "text/plain": [
       "[1] 0.6474806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(launch_prognosis(x=x,y=y,predictors=c(predictorRFX),str_predictors=str_predictors,l_alpha=l_alpha,l_ntree=l_ntree,mc.cores=1,nodesize=c(10,20),nrepeats=2,nfolds=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"start CV\"\n",
      "........................."
     ]
    },
    {
     "data": {
      "text/html": [
       "0.648022746792529"
      ],
      "text/latex": [
       "0.648022746792529"
      ],
      "text/markdown": [
       "0.648022746792529"
      ],
      "text/plain": [
       "[1] 0.6480227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(launch_prognosis(x,y,c(predictorRF),str_predictors,l_alpha,l_ntree,mc.cores=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (designTrain, designTest, responseTrain, max.iter = 500, \n",
       "<span style=white-space:pre-wrap>    tol = 1e-04) </span>\n",
       "{\n",
       "<span style=white-space:pre-wrap>    set.seed(17)</span>\n",
       "<span style=white-space:pre-wrap>    cvfit = CoxRFX(data.frame(designTrain), Surv(time = responseTrain[, </span>\n",
       "<span style=white-space:pre-wrap>        1], event = responseTrain[, 2]), max.iter = max.iter, </span>\n",
       "<span style=white-space:pre-wrap>        tol = tol)</span>\n",
       "<span style=white-space:pre-wrap>    cvfit$Z &lt;- NULL</span>\n",
       "<span style=white-space:pre-wrap>    risk.predict &lt;- predict(cvfit, data.frame(designTest))</span>\n",
       "<span style=white-space:pre-wrap>    return(risk.predict)</span>\n",
       "}</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (designTrain, designTest, responseTrain, max.iter = 500, \n",
       "    tol = 1e-04) \n",
       "\\{\n",
       "    set.seed(17)\n",
       "    cvfit = CoxRFX(data.frame(designTrain), Surv(time = responseTrain{[}, \n",
       "        1{]}, event = responseTrain{[}, 2{]}), max.iter = max.iter, \n",
       "        tol = tol)\n",
       "    cvfit\\$Z <- NULL\n",
       "    risk.predict <- predict(cvfit, data.frame(designTest))\n",
       "    return(risk.predict)\n",
       "\\}\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (designTrain, designTest, responseTrain, max.iter = 500, \n",
       "    tol = 1e-04) \n",
       "{\n",
       "    set.seed(17)\n",
       "    cvfit = CoxRFX(data.frame(designTrain), Surv(time = responseTrain[, \n",
       "        1], event = responseTrain[, 2]), max.iter = max.iter, \n",
       "        tol = tol)\n",
       "    cvfit$Z <- NULL\n",
       "    risk.predict <- predict(cvfit, data.frame(designTest))\n",
       "    return(risk.predict)\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "function (designTrain, designTest, responseTrain, max.iter = 500, \n",
       "    tol = 1e-04) \n",
       "{\n",
       "    set.seed(17)\n",
       "    cvfit = CoxRFX(data.frame(designTrain), Surv(time = responseTrain[, \n",
       "        1], event = responseTrain[, 2]), max.iter = max.iter, \n",
       "        tol = tol)\n",
       "    cvfit$Z <- NULL\n",
       "    risk.predict <- predict(cvfit, data.frame(designTest))\n",
       "    return(risk.predict)\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictorRFX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for CoxRFX {CoxHD}\"><tr><td>CoxRFX {CoxHD}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Cox proportional hazards model with random effects</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>This function estimates a Cox proportional in which the parameters follow normal distributions as discussed by Therneau et al. (2003).\n",
       "Multiple groups can be defined with different prior mean and variance.\n",
       "The variances of the joint distributions are efficiently estimated by an EM-type algorithm.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "CoxRFX(Z, surv, groups = rep(1, ncol(Z)), which.mu = unique(groups),\n",
       "  tol = 0.001, max.iter = 50, sigma0 = 0.1, nu = 0,\n",
       "  penalize.mu = FALSE, sigma.hat = c(\"df\", \"MLE\", \"REML\", \"BLUP\"),\n",
       "  verbose = FALSE)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>Z</code></td>\n",
       "<td>\n",
       "<p>The data matrix of random effects (n x p)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>surv</code></td>\n",
       "<td>\n",
       "<p>The survival object (n x 2)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>groups</code></td>\n",
       "<td>\n",
       "<p>Optional groups as a factor (p) with l levels. Default = rep(1, n)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>which.mu</code></td>\n",
       "<td>\n",
       "<p>Indicator which of the groups should have an offset. Default = unique(groups)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>tol</code></td>\n",
       "<td>\n",
       "<p>The tolerance beyond which to stop</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>max.iter</code></td>\n",
       "<td>\n",
       "<p>The maximal number of iterations</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sigma0</code></td>\n",
       "<td>\n",
       "<p>The variance of a si-chisq hyperprior on the variances.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nu</code></td>\n",
       "<td>\n",
       "<p>The df of the variance hyperprior. Default = 0, that is no hyperprior.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>penalize.mu</code></td>\n",
       "<td>\n",
       "<p>Wether to define an N(0,tau) hyperprior on the group means.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sigma.hat</code></td>\n",
       "<td>\n",
       "<p>Which estimator to use for the variances. Default df, other possibilities include MLE, REML and BLUP, see details.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>verbose</code></td>\n",
       "<td>\n",
       "<p>Gives more output.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The values of the means mu_g are estimated using the rowSums of Z (within in group) as auxillary variables.\n",
       "</p>\n",
       "<p>Different estimators exist for the variances sigma2_g: The default is &quot;df&quot;, as used by Perperoglou (2014) and introduced by Schall (1991). In the M-step of the algorithm, this uses sigma^2_g = beta_g beta_g^T/df_g, where the degrees\n",
       "of freedom df_g = tr H_gg are the trace of the Hessian matrix over the elements of group g. Alternatives are MLE, REML, and BLUP, as defined by Therneau et al. (2003).\n",
       "Simulations indicate that the 'df' method is most accurate.\n",
       "</p>\n",
       "<p>The model is equivalent to coxme(surv ~ (Z1|1) + rowSums(Z1) + (Z2|1) + rowSums(Z2) + ...); the coxme routine numerically optimises the integrated partial likelihood, which may\n",
       "be more accurate, but is computationally expensive.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A coxph object with a few extra fields: $groups, $Z, $surv, $sigma2 (the variances), $mu (the means), $Hinv (the inverse Hessian of the penalised likelihood), $V = Hinv I Hinv, the covariance of all coefficients and means,\n",
       "$C the map between centred (beta', mu) to beta.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>mg14\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Terry M Therneau, Patricia M Grambsch &amp; V. Shane Pankratz (2003) Penalized Survival Models and Frailty, Journal of Computational and Graphical Statistics, 12:1, 156-175, http://dx.doi.org/10.1198/1061860031365\n",
       "</p>\n",
       "<p>A. Perperoglou (2014). Cox models with dynamic ridge penalties on time-varying effects of the covariates. Stat Med, 33:170-80. http://dx.doi.org/10.1002/sim.5921\n",
       "</p>\n",
       "<p>R. Schall (1991). Estimation in generalized linear models with random effects. Biometrika, 78:719-727. http://dx.doi.org/10.1093/biomet/78.4.719\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "#' ### Parameters\n",
       "#' First define some parameters\n",
       "#+ parameters\n",
       "set.seed(42)\n",
       "nParam = 250 # Parameters\n",
       "nObs = 1000 # Observations\n",
       "nGroups &lt;- 5\n",
       "groups &lt;- factor(paste(\"Group\", rep(1:nGroups, each=nParam/nGroups)))\n",
       "\n",
       "#' Now draw coefficients\n",
       "#+ coefficients\n",
       "require(mvtnorm)\n",
       "mu &lt;- seq(-0.5,0.5,l=nGroups) # Coefficient mean within each group \n",
       "sd &lt;- seq(0.1,1, l=nGroups)  # Standard deviations\n",
       "a &lt;- rnorm(nParam, mean = rep(mu, each=50), sd = rep(sd, each=50)) # Normal coefficients\n",
       "beta = rbeta(nParam, 1, 20)\n",
       "Z &lt;- rmvnorm(nObs, mean=rep(0,nParam), sigma = diag(beta) + 1e-3) # Normal covariates with a bit of correlation\n",
       "Z[] &lt;- Z &gt; quantile(Z, 0.75) ## Make binary\n",
       "cor(Z[,1:5])\n",
       "\n",
       "#' Simulated risk\n",
       "#+ risk\n",
       "risk = Z %*% a\n",
       "a &lt;- a / sd(risk) # standardize\n",
       "mu &lt;- mu / sd(risk) # standardize\n",
       "sd &lt;- sd / sd(risk) # standardize\n",
       "risk &lt;- risk / sd(risk) # standardize\n",
       "head(risk)\n",
       "\n",
       "#' By group\n",
       "#+ groups\n",
       "riskComponents &lt;- sapply(levels(groups), function(g)  Z[,groups==g] %*% a[groups==g])\n",
       "cov(riskComponents)\n",
       "rowSums(cov(riskComponents))\n",
       "\n",
       "#' ### Simulate survival\n",
       "#+ survival\n",
       "surv = CoxHD:::SimSurv(risk = risk)\n",
       "plot(survfit(surv ~1))\n",
       "\n",
       "#' Maximal concordance\n",
       "survConcordance(surv ~ risk)\n",
       "\n",
       "#' ### Fit model\n",
       "#+ fit\n",
       "fit &lt;-  CoxRFX(Z, surv, groups = groups) ## takes about 30 s\n",
       "fit\n",
       "plot(fit)\n",
       "\n",
       "#' Coefficients\n",
       "WaldTest(fit)\n",
       "plot(a, coef(fit), col=fit$groups)\n",
       "segments(a, coef(fit) - 2*sqrt(diag(fit$var2)),a, coef(fit) + 2*sqrt(diag(fit$var2)), col=fit$groups)\n",
       "abline(0,1)\n",
       "\n",
       "#' Means\n",
       "plot(mu, fit$mu, col=1:nlevels(groups))\n",
       "segments(mu,fit$mu - 2*sqrt(diag(fit$mu.var2)) , mu, fit$mu + 2*sqrt(diag(fit$mu.var2)), col=1:nlevels(groups))\n",
       "abline(0,1)\n",
       "\n",
       "#' Variances\n",
       "plot(sd^2, fit$sigma2)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>CoxHD</em> version 0.0.61 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{CoxRFX}{Cox proportional hazards model with random effects}{CoxRFX}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "This function estimates a Cox proportional in which the parameters follow normal distributions as discussed by Therneau et al. (2003).\n",
       "Multiple groups can be defined with different prior mean and variance.\n",
       "The variances of the joint distributions are efficiently estimated by an EM-type algorithm.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "CoxRFX(Z, surv, groups = rep(1, ncol(Z)), which.mu = unique(groups),\n",
       "  tol = 0.001, max.iter = 50, sigma0 = 0.1, nu = 0,\n",
       "  penalize.mu = FALSE, sigma.hat = c(\"df\", \"MLE\", \"REML\", \"BLUP\"),\n",
       "  verbose = FALSE)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{Z}] The data matrix of random effects (n x p)\n",
       "\n",
       "\\item[\\code{surv}] The survival object (n x 2)\n",
       "\n",
       "\\item[\\code{groups}] Optional groups as a factor (p) with l levels. Default = rep(1, n)\n",
       "\n",
       "\\item[\\code{which.mu}] Indicator which of the groups should have an offset. Default = unique(groups)\n",
       "\n",
       "\\item[\\code{tol}] The tolerance beyond which to stop\n",
       "\n",
       "\\item[\\code{max.iter}] The maximal number of iterations\n",
       "\n",
       "\\item[\\code{sigma0}] The variance of a si-chisq hyperprior on the variances.\n",
       "\n",
       "\\item[\\code{nu}] The df of the variance hyperprior. Default = 0, that is no hyperprior.\n",
       "\n",
       "\\item[\\code{penalize.mu}] Wether to define an N(0,tau) hyperprior on the group means.\n",
       "\n",
       "\\item[\\code{sigma.hat}] Which estimator to use for the variances. Default df, other possibilities include MLE, REML and BLUP, see details.\n",
       "\n",
       "\\item[\\code{verbose}] Gives more output.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The values of the means mu\\_g are estimated using the rowSums of Z (within in group) as auxillary variables.\n",
       "\n",
       "Different estimators exist for the variances sigma2\\_g: The default is \"df\", as used by Perperoglou (2014) and introduced by Schall (1991). In the M-step of the algorithm, this uses sigma\\textasciicircum{}2\\_g = beta\\_g beta\\_g\\textasciicircum{}T/df\\_g, where the degrees\n",
       "of freedom df\\_g = tr H\\_gg are the trace of the Hessian matrix over the elements of group g. Alternatives are MLE, REML, and BLUP, as defined by Therneau et al. (2003).\n",
       "Simulations indicate that the 'df' method is most accurate.\n",
       "\n",
       "The model is equivalent to coxme(surv \\textasciitilde{} (Z1|1) + rowSums(Z1) + (Z2|1) + rowSums(Z2) + ...); the coxme routine numerically optimises the integrated partial likelihood, which may\n",
       "be more accurate, but is computationally expensive.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A coxph object with a few extra fields: \\$groups, \\$Z, \\$surv, \\$sigma2 (the variances), \\$mu (the means), \\$Hinv (the inverse Hessian of the penalised likelihood), \\$V = Hinv I Hinv, the covariance of all coefficients and means,\n",
       "\\$C the map between centred (beta', mu) to beta.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "mg14\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Terry M Therneau, Patricia M Grambsch \\& V. Shane Pankratz (2003) Penalized Survival Models and Frailty, Journal of Computational and Graphical Statistics, 12:1, 156-175, http://dx.doi.org/10.1198/1061860031365\n",
       "\n",
       "A. Perperoglou (2014). Cox models with dynamic ridge penalties on time-varying effects of the covariates. Stat Med, 33:170-80. http://dx.doi.org/10.1002/sim.5921\n",
       "\n",
       "R. Schall (1991). Estimation in generalized linear models with random effects. Biometrika, 78:719-727. http://dx.doi.org/10.1093/biomet/78.4.719\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "#' ### Parameters\n",
       "#' First define some parameters\n",
       "#+ parameters\n",
       "set.seed(42)\n",
       "nParam = 250 # Parameters\n",
       "nObs = 1000 # Observations\n",
       "nGroups <- 5\n",
       "groups <- factor(paste(\"Group\", rep(1:nGroups, each=nParam/nGroups)))\n",
       "\n",
       "#' Now draw coefficients\n",
       "#+ coefficients\n",
       "require(mvtnorm)\n",
       "mu <- seq(-0.5,0.5,l=nGroups) # Coefficient mean within each group \n",
       "sd <- seq(0.1,1, l=nGroups)  # Standard deviations\n",
       "a <- rnorm(nParam, mean = rep(mu, each=50), sd = rep(sd, each=50)) # Normal coefficients\n",
       "beta = rbeta(nParam, 1, 20)\n",
       "Z <- rmvnorm(nObs, mean=rep(0,nParam), sigma = diag(beta) + 1e-3) # Normal covariates with a bit of correlation\n",
       "Z[] <- Z > quantile(Z, 0.75) ## Make binary\n",
       "cor(Z[,1:5])\n",
       "\n",
       "#' Simulated risk\n",
       "#+ risk\n",
       "risk = Z %*% a\n",
       "a <- a / sd(risk) # standardize\n",
       "mu <- mu / sd(risk) # standardize\n",
       "sd <- sd / sd(risk) # standardize\n",
       "risk <- risk / sd(risk) # standardize\n",
       "head(risk)\n",
       "\n",
       "#' By group\n",
       "#+ groups\n",
       "riskComponents <- sapply(levels(groups), function(g)  Z[,groups==g] %*% a[groups==g])\n",
       "cov(riskComponents)\n",
       "rowSums(cov(riskComponents))\n",
       "\n",
       "#' ### Simulate survival\n",
       "#+ survival\n",
       "surv = CoxHD:::SimSurv(risk = risk)\n",
       "plot(survfit(surv ~1))\n",
       "\n",
       "#' Maximal concordance\n",
       "survConcordance(surv ~ risk)\n",
       "\n",
       "#' ### Fit model\n",
       "#+ fit\n",
       "fit <-  CoxRFX(Z, surv, groups = groups) ## takes about 30 s\n",
       "fit\n",
       "plot(fit)\n",
       "\n",
       "#' Coefficients\n",
       "WaldTest(fit)\n",
       "plot(a, coef(fit), col=fit$groups)\n",
       "segments(a, coef(fit) - 2*sqrt(diag(fit$var2)),a, coef(fit) + 2*sqrt(diag(fit$var2)), col=fit$groups)\n",
       "abline(0,1)\n",
       "\n",
       "#' Means\n",
       "plot(mu, fit$mu, col=1:nlevels(groups))\n",
       "segments(mu,fit$mu - 2*sqrt(diag(fit$mu.var2)) , mu, fit$mu + 2*sqrt(diag(fit$mu.var2)), col=1:nlevels(groups))\n",
       "abline(0,1)\n",
       "\n",
       "#' Variances\n",
       "plot(sd^2, fit$sigma2)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "CoxRFX                  package:CoxHD                  R Documentation\n",
       "\n",
       "_\bC_\bo_\bx _\bp_\br_\bo_\bp_\bo_\br_\bt_\bi_\bo_\bn_\ba_\bl _\bh_\ba_\bz_\ba_\br_\bd_\bs _\bm_\bo_\bd_\be_\bl _\bw_\bi_\bt_\bh _\br_\ba_\bn_\bd_\bo_\bm _\be_\bf_\bf_\be_\bc_\bt_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     This function estimates a Cox proportional in which the parameters\n",
       "     follow normal distributions as discussed by Therneau et al.\n",
       "     (2003). Multiple groups can be defined with different prior mean\n",
       "     and variance. The variances of the joint distributions are\n",
       "     efficiently estimated by an EM-type algorithm.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     CoxRFX(Z, surv, groups = rep(1, ncol(Z)), which.mu = unique(groups),\n",
       "       tol = 0.001, max.iter = 50, sigma0 = 0.1, nu = 0,\n",
       "       penalize.mu = FALSE, sigma.hat = c(\"df\", \"MLE\", \"REML\", \"BLUP\"),\n",
       "       verbose = FALSE)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       Z: The data matrix of random effects (n x p)\n",
       "\n",
       "    surv: The survival object (n x 2)\n",
       "\n",
       "  groups: Optional groups as a factor (p) with l levels. Default =\n",
       "          rep(1, n)\n",
       "\n",
       "which.mu: Indicator which of the groups should have an offset. Default\n",
       "          = unique(groups)\n",
       "\n",
       "     tol: The tolerance beyond which to stop\n",
       "\n",
       "max.iter: The maximal number of iterations\n",
       "\n",
       "  sigma0: The variance of a si-chisq hyperprior on the variances.\n",
       "\n",
       "      nu: The df of the variance hyperprior. Default = 0, that is no\n",
       "          hyperprior.\n",
       "\n",
       "penalize.mu: Wether to define an N(0,tau) hyperprior on the group\n",
       "          means.\n",
       "\n",
       "sigma.hat: Which estimator to use for the variances. Default df, other\n",
       "          possibilities include MLE, REML and BLUP, see details.\n",
       "\n",
       " verbose: Gives more output.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The values of the means mu_g are estimated using the rowSums of Z\n",
       "     (within in group) as auxillary variables.\n",
       "\n",
       "     Different estimators exist for the variances sigma2_g: The default\n",
       "     is \"df\", as used by Perperoglou (2014) and introduced by Schall\n",
       "     (1991). In the M-step of the algorithm, this uses sigma^2_g =\n",
       "     beta_g beta_g^T/df_g, where the degrees of freedom df_g = tr H_gg\n",
       "     are the trace of the Hessian matrix over the elements of group g.\n",
       "     Alternatives are MLE, REML, and BLUP, as defined by Therneau et\n",
       "     al. (2003). Simulations indicate that the 'df' method is most\n",
       "     accurate.\n",
       "\n",
       "     The model is equivalent to coxme(surv ~ (Z1|1) + rowSums(Z1) +\n",
       "     (Z2|1) + rowSums(Z2) + ...); the coxme routine numerically\n",
       "     optimises the integrated partial likelihood, which may be more\n",
       "     accurate, but is computationally expensive.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A coxph object with a few extra fields: $groups, $Z, $surv,\n",
       "     $sigma2 (the variances), $mu (the means), $Hinv (the inverse\n",
       "     Hessian of the penalised likelihood), $V = Hinv I Hinv, the\n",
       "     covariance of all coefficients and means, $C the map between\n",
       "     centred (beta', mu) to beta.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     mg14\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Terry M Therneau, Patricia M Grambsch & V. Shane Pankratz (2003)\n",
       "     Penalized Survival Models and Frailty, Journal of Computational\n",
       "     and Graphical Statistics, 12:1, 156-175,\n",
       "     http://dx.doi.org/10.1198/1061860031365\n",
       "\n",
       "     A. Perperoglou (2014). Cox models with dynamic ridge penalties on\n",
       "     time-varying effects of the covariates. Stat Med, 33:170-80.\n",
       "     http://dx.doi.org/10.1002/sim.5921\n",
       "\n",
       "     R. Schall (1991). Estimation in generalized linear models with\n",
       "     random effects. Biometrika, 78:719-727.\n",
       "     http://dx.doi.org/10.1093/biomet/78.4.719\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     #' ### Parameters\n",
       "     #' First define some parameters\n",
       "     #+ parameters\n",
       "     set.seed(42)\n",
       "     nParam = 250 # Parameters\n",
       "     nObs = 1000 # Observations\n",
       "     nGroups <- 5\n",
       "     groups <- factor(paste(\"Group\", rep(1:nGroups, each=nParam/nGroups)))\n",
       "     \n",
       "     #' Now draw coefficients\n",
       "     #+ coefficients\n",
       "     require(mvtnorm)\n",
       "     mu <- seq(-0.5,0.5,l=nGroups) # Coefficient mean within each group \n",
       "     sd <- seq(0.1,1, l=nGroups)  # Standard deviations\n",
       "     a <- rnorm(nParam, mean = rep(mu, each=50), sd = rep(sd, each=50)) # Normal coefficients\n",
       "     beta = rbeta(nParam, 1, 20)\n",
       "     Z <- rmvnorm(nObs, mean=rep(0,nParam), sigma = diag(beta) + 1e-3) # Normal covariates with a bit of correlation\n",
       "     Z[] <- Z > quantile(Z, 0.75) ## Make binary\n",
       "     cor(Z[,1:5])\n",
       "     \n",
       "     #' Simulated risk\n",
       "     #+ risk\n",
       "     risk = Z %*% a\n",
       "     a <- a / sd(risk) # standardize\n",
       "     mu <- mu / sd(risk) # standardize\n",
       "     sd <- sd / sd(risk) # standardize\n",
       "     risk <- risk / sd(risk) # standardize\n",
       "     head(risk)\n",
       "     \n",
       "     #' By group\n",
       "     #+ groups\n",
       "     riskComponents <- sapply(levels(groups), function(g)  Z[,groups==g] %*% a[groups==g])\n",
       "     cov(riskComponents)\n",
       "     rowSums(cov(riskComponents))\n",
       "     \n",
       "     #' ### Simulate survival\n",
       "     #+ survival\n",
       "     surv = CoxHD:::SimSurv(risk = risk)\n",
       "     plot(survfit(surv ~1))\n",
       "     \n",
       "     #' Maximal concordance\n",
       "     survConcordance(surv ~ risk)\n",
       "     \n",
       "     #' ### Fit model\n",
       "     #+ fit\n",
       "     fit <-  CoxRFX(Z, surv, groups = groups) ## takes about 30 s\n",
       "     fit\n",
       "     plot(fit)\n",
       "     \n",
       "     #' Coefficients\n",
       "     WaldTest(fit)\n",
       "     plot(a, coef(fit), col=fit$groups)\n",
       "     segments(a, coef(fit) - 2*sqrt(diag(fit$var2)),a, coef(fit) + 2*sqrt(diag(fit$var2)), col=fit$groups)\n",
       "     abline(0,1)\n",
       "     \n",
       "     #' Means\n",
       "     plot(mu, fit$mu, col=1:nlevels(groups))\n",
       "     segments(mu,fit$mu - 2*sqrt(diag(fit$mu.var2)) , mu, fit$mu + 2*sqrt(diag(fit$mu.var2)), col=1:nlevels(groups))\n",
       "     abline(0,1)\n",
       "     \n",
       "     #' Variances\n",
       "     plot(sd^2, fit$sigma2)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "help(CoxRFX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
