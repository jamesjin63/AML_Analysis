{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv(\"../../../data/initial_dataset/Master_04_10_2019.csv\",sep=\",\",low_memory=False)\n",
    "df_master = df_master.drop(df_master.columns[[0,1]],1)\n",
    "df_itd = pd.read_csv(\"../../../data/updated_dataset/ITD_merge_updated.csv\",sep=\",\",low_memory=False)\n",
    "df_itd = df_itd.drop(df_itd.columns[0],1)\n",
    "df_merge = pd.merge(df_master,df_itd, on='data_pd', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RULES :\n",
    "\n",
    "We start from initial dataframe that was given to me.\n",
    "\n",
    "1) Replace FLT3_ITD by new column ITD where we have set up the rules.\n",
    "\n",
    "2) Additions : sum (p and q) and return 1 if sum >=1 for each chromosome . ex : add_10 = add_10p+add_10q\n",
    "\n",
    "3) Deletions : exactly the same . ex: del_10 = del_10p +del_10q\n",
    "\n",
    "4) Keep only new columns additions and deletions with frequency >=2%\n",
    "\n",
    "5) Translocations : Keep all translocations that appear at least two times. For translocations that appear only once : create a new column \"other transloc\" to sum all those translocation and return 1 when value is >=1\n",
    "\n",
    "6) Inversions : There is only one inversion with frequency greater than 2% (inv  16). we will add inv3 because it creates its own cluster with SF3B1. (We will not do this in this notebook).\n",
    "\n",
    "7) Replace complex columns by : 1 if sumn of aneuploidies (any additions and any deletions is >=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame with all genomics and cytogenetic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of genomic features: 83\n",
      "number of cyto features: 355\n",
      "number of genomic + cyto features: 438\n",
      "number of genomic + cyto features + id features: 440\n"
     ]
    }
   ],
   "source": [
    "df_w_transloc = df_merge.loc[:,'ASXL1':'ZRSR2']\n",
    "print ('number of genomic features: '+str(df_w_transloc.shape[1]))\n",
    "df_w_transloc=df_w_transloc.join(df_merge.loc[:,'t_v_11':'complex'])\n",
    "print ('number of cyto features: '+str(df_merge.loc[:,'t_v_11':'complex'].shape[1]))\n",
    "print ('number of genomic + cyto features: '+ str(df_w_transloc.shape[1]))\n",
    "df_w_transloc = df_merge.loc[:,['data_pd','sample_pd']].join(df_w_transloc)\n",
    "print ('number of genomic + cyto features + id features: '+ str(df_w_transloc.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Replace FLT3_ITD by Merge_ITD_new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2427, 440)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_w_transloc['FLT3_ITD'] = df_merge['Merge_ITD_new_rules']\n",
    "df_w_transloc.rename(columns={'FLT3_ITD':'ITD'},inplace=True)\n",
    "print (df_w_transloc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of NaN rows that are present because of NaN values in the translocation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 277 rows with Nan values in this translocation features\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(df_w_transloc[df_w_transloc.t_13_19.isna()].shape[0])+' rows with Nan values in this translocation features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's get rid of them (unfortunately the size of the dataset is going to decrease by those number of rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The final dataset without those NaN values and with all genomics and translocation features is as follow: (we also save it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2150, 440)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_transloc = df_w_transloc[~df_w_transloc.t_13_19.isna()]  # (Those rows have Nans for all translocations and lots of cyto events)\n",
    "df_w_transloc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Rules for Cyto events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome : 1 with Freqency(%) 1.5348837209302326\n",
      "Chromosome : 2 with Freqency(%) 0.9767441860465116\n",
      "Chromosome : 3 with Freqency(%) 1.302325581395349\n",
      "Chromosome : 4 with Freqency(%) 1.5813953488372092\n",
      "Chromosome : 5 with Freqency(%) 0.8837209302325582\n",
      "Chromosome : 6 with Freqency(%) 1.9534883720930232\n",
      "Chromosome : 7 with Freqency(%) 1.3488372093023255\n",
      "Chromosome : 8 with Freqency(%) 10.232558139534884\n",
      "Chromosome : 9 with Freqency(%) 1.6744186046511629\n",
      "Chromosome : 10 with Freqency(%) 0.9767441860465116\n",
      "Chromosome : 11 with Freqency(%) 3.953488372093023\n",
      "Chromosome : 12 with Freqency(%) 1.1627906976744187\n",
      "Chromosome : 13 with Freqency(%) 2.2325581395348837\n",
      "Chromosome : 14 with Freqency(%) 1.441860465116279\n",
      "Chromosome : 15 with Freqency(%) 0.8372093023255814\n",
      "Chromosome : 16 with Freqency(%) 1.069767441860465\n",
      "Chromosome : 17 with Freqency(%) 1.6744186046511629\n",
      "Chromosome : 18 with Freqency(%) 0.6976744186046512\n",
      "Chromosome : 19 with Freqency(%) 1.8604651162790697\n",
      "Chromosome : 20 with Freqency(%) 0.9767441860465116\n",
      "Chromosome : 21 with Freqency(%) 3.7209302325581395\n",
      "Chromosome : 22 with Freqency(%) 2.744186046511628\n",
      "Chromosome : x with Freqency(%) 0.46511627906976744\n",
      "Chromosome : y with Freqency(%) 0.27906976744186046\n",
      "\n",
      "We keep : ['add_8', 'add_11', 'add_13', 'add_21', 'add_22']\n"
     ]
    }
   ],
   "source": [
    "tmp_add = df_w_transloc.loc[:,'add_10p':'add_xq']\n",
    "tmp_add = pd.concat([tmp_add,df_w_transloc.loc[:,'plus1':'plusy']],1)\n",
    "to_keep = []\n",
    "for i in range(1,23):\n",
    "    tmp_add['add_'+str(i)] = tmp_add['add_'+str(i)+'p']+tmp_add['add_'+str(i)+'q']+tmp_add['plus'+str(i)]\n",
    "    freq = 100*sum(tmp_add['add_'+str(i)])/tmp_add.shape[0]\n",
    "    print ('Chromosome : '+str(i)+' with Freqency(%)', freq)\n",
    "    to_keep +=['add_'+str(i) if freq >=2 else '']\n",
    "    \n",
    "tmp_add['add_x'] = tmp_add['add_xp']+tmp_add['add_xq']+tmp_add['plusx']\n",
    "freq = 100*sum(tmp_add['add_x'])/tmp_add.shape[0]\n",
    "print ('Chromosome : x with Freqency(%)', freq)\n",
    "to_keep +=['add_x' if freq >=2 else '']\n",
    "\n",
    "freq = 100*sum(tmp_add['plusy'])/tmp_add.shape[0]\n",
    "print ('Chromosome : y with Freqency(%)', freq)\n",
    "to_keep +=['plusy' if freq >=2 else '']\n",
    "\n",
    "\n",
    "to_keep= [t for t in to_keep if t!='']\n",
    "print()\n",
    "print('We keep : '+ str(to_keep))\n",
    "tmp_add = tmp_add[to_keep]\n",
    "tmp_add[tmp_add>1]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome : 4 with Freqency(%) 1.3953488372093024\n",
      "Chromosome : 14 with Freqency(%) 0.9767441860465116\n",
      "Chromosome : 20 with Freqency(%) 2.744186046511628\n",
      "Chromosome : 21 with Freqency(%) 1.5813953488372092\n",
      "Chromosome : 22 with Freqency(%) 1.2093023255813953\n",
      "Chromosome : 1 with Freqency(%) 0.6046511627906976\n",
      "Chromosome : 2 with Freqency(%) 0.9767441860465116\n",
      "Chromosome : 3 with Freqency(%) 2.13953488372093\n",
      "Chromosome : 5 with Freqency(%) 7.162790697674419\n",
      "Chromosome : 6 with Freqency(%) 1.2093023255813953\n",
      "Chromosome : 7 with Freqency(%) 8.883720930232558\n",
      "Chromosome : 8 with Freqency(%) 0.5116279069767442\n",
      "Chromosome : 9 with Freqency(%) 3.0232558139534884\n",
      "Chromosome : 10 with Freqency(%) 0.6511627906976745\n",
      "Chromosome : 11 with Freqency(%) 1.6744186046511629\n",
      "Chromosome : 12 with Freqency(%) 2.7906976744186047\n",
      "Chromosome : 13 with Freqency(%) 2.186046511627907\n",
      "Chromosome : 15 with Freqency(%) 1.1162790697674418\n",
      "Chromosome : 16 with Freqency(%) 2.3255813953488373\n",
      "Chromosome : 17 with Freqency(%) 3.5348837209302326\n",
      "Chromosome : 18 with Freqency(%) 2.604651162790698\n",
      "Chromosome : 19 with Freqency(%) 0.5581395348837209\n",
      "Chromosome : x with Freqency(%) 1.3488372093023255\n",
      "Chromosome : y with Freqency(%) 3.441860465116279\n",
      "\n",
      "We keep : ['del_20', 'del_3', 'del_5', 'del_7', 'del_9', 'del_12', 'del_13', 'del_16', 'del_17', 'del_18', 'minusy']\n"
     ]
    }
   ],
   "source": [
    "tmp_del = df_w_transloc.loc[:,'del_10p':'del_xq']\n",
    "tmp_del = pd.concat([tmp_del,df_w_transloc.loc[:,'minus1':'minusy']],1)\n",
    "tmp_del.drop(['minus7.'],1,inplace=True)\n",
    "to_keep = []\n",
    "list_p_missing = ['4', '14', '20', '21', '22']\n",
    "list_with_p = ['1', '2', '3', '5', '6', '7', '8', '9', '10', '11', '12', '13', '15', '16', '17', '18', '19',  ]\n",
    "for l in list_p_missing:\n",
    "    tmp_del['del_'+l] = tmp_del['del_'+l+'q'] + tmp_del['minus'+l]\n",
    "    freq = 100*sum(tmp_del['del_'+l])/tmp_del.shape[0]\n",
    "    print ('Chromosome : '+l+' with Freqency(%)', freq)\n",
    "    to_keep +=['del_'+l if freq >=2 else '']\n",
    "    \n",
    "for l in list_with_p:\n",
    "    tmp_del['del_'+l] = tmp_del['del_'+l+'p'] + tmp_del['del_'+l+'q'] + tmp_del['minus'+l]\n",
    "    freq = 100*sum(tmp_del['del_'+l])/tmp_del.shape[0]\n",
    "    print ('Chromosome : '+l+' with Freqency(%)', freq)\n",
    "    to_keep +=['del_'+l if freq >=2 else '']\n",
    "    \n",
    "tmp_del['del_x'] = tmp_del['del_xq'] + tmp_del['minusx'] \n",
    "freq = 100*sum(tmp_del['del_x'])/tmp_del.shape[0]\n",
    "to_keep +=['del_x' if freq >=2 else '']\n",
    "print ('Chromosome : x with Freqency(%)', 100*sum(tmp_del['del_x'])/tmp_del.shape[0])\n",
    "\n",
    "freq = 100*sum(tmp_del['minusy'])/tmp_del.shape[0]\n",
    "to_keep +=['minusy' if freq >=2 else '']\n",
    "print ('Chromosome : y with Freqency(%)', 100*sum(tmp_del['minusy'])/tmp_del.shape[0])\n",
    "\n",
    "to_keep= [t for t in to_keep if t!='']\n",
    "print()\n",
    "print('We keep : '+ str(to_keep))\n",
    "tmp_del = tmp_del[to_keep]\n",
    "tmp_del[tmp_del>1]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Translocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transloc = df_w_transloc.loc[:,'t_v_11':'complex']\n",
    "#transloc.tail()\n",
    "transloc.loc['count']=transloc.sum()\n",
    "high_count = pd.DataFrame(transloc.loc['count'].T)\n",
    "transloc_keep = high_count[((high_count['count']>=2) & ((high_count.index.str.contains(\"t_\"))|(high_count.index==\"complex\"))) ].index\n",
    "transloc_to_sum = high_count[(high_count['count']<2) & ((high_count.index.str.contains(\"t_\")))].index\n",
    "tmp_others = df_w_transloc.loc[:,transloc_keep]\n",
    "tmp_others['others_transloc'] = transloc.loc[:,transloc_to_sum].sum(axis = 1)\n",
    "tmp_others.others_transloc[tmp_others.others_transloc>1]=1\n",
    "tmp_others.columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Check frequency of inversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inv_1     0.186047\n",
       "inv_10    0.139535\n",
       "inv_11    0.139535\n",
       "inv_12    0.046512\n",
       "inv_16    4.372093\n",
       "inv_17    0.046512\n",
       "inv_2     0.093023\n",
       "inv_3     1.023256\n",
       "inv_4     0.046512\n",
       "inv_5     0.093023\n",
       "inv_6     0.046512\n",
       "inv_7     0.232558\n",
       "inv_8     0.186047\n",
       "inv_9     0.139535\n",
       "inv_x     0.046512\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transloc = df_w_transloc.loc[:,[col for col in df_w_transloc if col.startswith('inv')]]\n",
    "transloc.loc['count']=100*transloc.sum()/transloc.shape[0]\n",
    "transloc.loc['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 All together in a datframe with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2150, 85)\n",
      "(2150, 90)\n",
      "(2150, 101)\n",
      "Final df for clustering dimensions :(2150, 153)\n"
     ]
    }
   ],
   "source": [
    "df_modif_final = df_w_transloc.loc[:,'data_pd':'ZRSR2']\n",
    "print(df_modif_final.shape) # 83 genomic features + 2 ids features\n",
    "df_modif_final = df_modif_final.join(tmp_add)\n",
    "print(df_modif_final.shape) # + 5 translocation addition features\n",
    "df_modif_final = df_modif_final.join(tmp_del) # + 11 deletion features\n",
    "print(df_modif_final.shape)\n",
    "df_modif_final = df_modif_final.join(tmp_others) # + 52 translocation features\n",
    "print('Final df for clustering dimensions :'+str(df_modif_final.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the types of the variables to make it uniform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('O') dtype('int64') dtype('float64')]\n",
      "[dtype('O') dtype('int64')]\n"
     ]
    }
   ],
   "source": [
    "print(df_modif_final.dtypes.unique())\n",
    "df_modif_final.iloc[:,2:] = df_modif_final.iloc[:,2:].astype(int)\n",
    "print(df_modif_final.dtypes.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_modif_final.to_csv(\"../../../data/updated_dataset/modif_final.csv\",sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
